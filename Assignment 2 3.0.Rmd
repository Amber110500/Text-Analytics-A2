---
title: "Text Analytics"
author: "Marijn van der Werff, Robbert Batenburg, Floris van Haarst & Amber Dalhuisen"
date: "2024-19-04"
output: 
  pdf_document:
    toc: true
    toc_depth: 2
subtitle: "Assignment 2"
urlcolor: blue
---

```{r, include=FALSE, echo=TRUE}
library(dplyr)
library(ggplot2)
library(tidytext)
library(SnowballC)
library(syuzhet)
library(tidyr)
library(qdap)
library(mgsub)
library(tm)
library(caret)
library(randomForest)
library(stringr)
library(plotmo)
library(glmnet)
library(pROC)
library(kableExtra)
library(gridExtra)
load("reviews_with_predictor_variables.rData")
```

```{r}
reviews_df <- read.csv("DisneylandReviews.csv")
reviews_df <- reviews_df[reviews_df$Branch == "Disneyland_HongKong",]

names(reviews_df)[1] <- "User_ID"
names(reviews_df)[5] <- "reviewtext"
reviews_df <- reviews_df[, c(1, 2, 5, 6)]

reviews_df$reviewtext <- as.character(reviews_df$reviewtext)  %>%
  tolower() %>%
  {gsub(":( |-|o)*\\("," SADSMILE ", .)} %>%        # Find :( or :-( or : ( or :o(
  {gsub(":( |-|o)*\\)"," HAPPYSMILE ", .)} %>%      # Find :) or :-) or : ) or :o)
  {gsub("\\n", " ", .)} %>%                        # Remove \n (newline)     
  {gsub("[?!]+",".",.)} %>%                        # Remove ? and ! (replace by single .)
  {gsub("[\\[\\*\\]]*"," ",.)} %>%                 # Remove [ and ] * (replace by single space)
  {gsub("(\"| |\\$)-+\\.-+"," number ", .)} %>%    # Find numbers
  {gsub("(-+:)*-+ *am"," timeam", .)} %>%          # Find time AM
  {gsub("(-+:)*-+ *pm"," timepm", .)} %>%          # Find time PM
  {gsub("-+:-+","time", .)} %>%                    # Find general time
  {gsub("( |\\$)--+"," number ", .)} %>%           # Find remaining numbers
  {gsub("-"," ", .)} %>%                           # Remove all -
  {gsub("\"+"," ", .)} %>%                         # Remove all "
  {gsub(";+"," ", .)} %>%                          # Remove excess ;
  {gsub("\\.+","\\. ", .)} %>%                     # Remove excess .
  {gsub(" +"," ", .)} %>%                          # Remove excess spaces
  {gsub("\\. \\.","\\. ", .)}                      # Remove space between periods

reviews_df_backup <- reviews_df


## REMOVE STOPWORDS ##

ignorelist = stop_words %>% filter(!word %in% c("no", "not", "never"))

for (j in 1:nrow(reviews_df)) {
  
  words <- reviews_df[j,] %>% 
    unnest_tokens(word, reviewtext) %>% 
    anti_join(ignorelist, by="word")
  
  stemmed <- wordStem(words[ , "word"], language = "porter")
  reviews_df[j, "stemmed_reviewtext_with_no"] <- paste(stemmed, collapse = " ")
  
  # Again, but with ignoring all stopwords
  nostopwords <- reviews_df[j,] %>% unnest_tokens(word, reviewtext) %>%
    anti_join( stop_words, by = "word")
  stemmed <- wordStem(nostopwords[ , "word"], language = "porter")
  
  # Add variables to data
  reviews_df[j, "stemmed_reviewtext"] <- paste(stemmed, collapse = " ")
  reviews_df[j, "reviewtext"] <- paste((nostopwords$word), collapse = " ")
  reviews_df[j, "Nr_of_words"]<- nrow(nostopwords)
}



### REMOVE (IN)FREQUENT WORDS ###


# Get word frequency after stemming
frequency  <- reviews_df %>% unnest_tokens(word, stemmed_reviewtext) %>% dplyr::count(word, sort=TRUE)

# Select very frequent or infrequent words
infrequent <- frequency %>% filter(n < 0.01*nrow(reviews_df))
frequent   <- frequency %>% filter(word %in% c("ride", "dai", "park", 'disneyland', "hong", "kong", "hk", "disnei")) # you can extend this list with word you want to remove
toremove   <- full_join(frequent, infrequent, by = "word")       # combining these word lists

# Remove common words from stemmed reviewtext
for (j in 1:nrow(reviews_df)) {
  tmp <-  anti_join( (reviews_df[j,] %>% unnest_tokens(word, stemmed_reviewtext) ), toremove, by = "word") 
  
  reviews_df[j,"stemmed_reviewtext"] <- paste(tmp[, "word"], collapse = " ")
}

save(reviews_df, file="Saved_reviews_df.Rda")
load("Saved_reviews_df.Rda")

# Changed order, first omit very frequent words that don't really have meaning, 
# Then make the bigrams using stemmed_reviewtext (not with no!)

### CREATE BIGRAMS ###

all_bigrams <- reviews_df[,c("User_ID", "stemmed_reviewtext")] %>% 
  unnest_tokens(bigram, stemmed_reviewtext, token = "ngrams", n = 2 )
#This ignores sentences within a review.. could be improved.

head(all_bigrams)
all_bigrams <- all_bigrams %>%  dplyr::count(bigram, sort = TRUE)
all_bigrams[1:20,]

sel_bigrams <- all_bigrams %>% filter(n>240)
sel_bigrams

# Separate the bigrams
bigrams_sep <-  separate(all_bigrams, bigram, c("word1", "word2"), sep = " ")
bigrams_sep[1:20,]




### CREATE SKIP NGRAMS ###
all_skip_ngrams <- reviews_df[,c("User_ID", "stemmed_reviewtext")] %>% 
  unnest_tokens(trigram, stemmed_reviewtext, token = "ngrams", n = 3 )

delete_middle_word <- function(column) {
  gsub("\\s+\\w+\\s+", " ", column)
}

# Apply function to each column
all_skip_ngrams <- lapply(all_skip_ngrams, delete_middle_word)
all_skip_ngrams <- as.data.frame(all_skip_ngrams)

all_skip_ngrams <- all_skip_ngrams %>%  dplyr::count(trigram, sort = TRUE)
all_skip_ngrams[1:20,]

sel_skip_ngrams <- all_skip_ngrams %>% filter(n>100) # 19 skip ngrams





### DTM FOR UNI AND BI-GRAMS ###

#Get document term matrix uni-grams
reviews_df$User_ID <- as.character(reviews_df$User_ID) 
reviews_df <- distinct(reviews_df, User_ID, .keep_all = TRUE) # Only include unique User_ID's
reviews_df$User_ID <- as.character(reviews_df$User_ID) %>% as.factor() 

# The factor may have more values than are actually present. 
# These are removed here, as this causes an error in prcomp

review_dtm <- reviews_df %>% 
  unnest_tokens(word, stemmed_reviewtext) %>% 
  dplyr::count(User_ID, word, sort=TRUE) %>% 
  ungroup() %>%
  cast_dtm(User_ID,word,n)

#Get document term matrix for bi-grams

review_dtm_bi <- reviews_df %>% 
  unnest_tokens(bigram, stemmed_reviewtext, token = "ngrams", n = 2) %>% 
  filter(bigram %in% sel_bigrams$bigram) %>%
  dplyr::count(User_ID, bigram, sort=TRUE)
review_dtm_bi$User_ID = as.character(review_dtm_bi$User_ID)

review_dtm_bi <- review_dtm_bi %>% 
  ungroup() %>%
  cast_dtm(User_ID, bigram, n)

# DTM for skip ngrams

review_dtm_skip <- reviews_df %>% 
  unnest_tokens(bigram, stemmed_reviewtext, token = "ngrams", n = 2) %>% 
  filter(bigram %in% sel_skip_ngrams$trigram) %>%
  dplyr::count(User_ID, bigram, sort=TRUE)
review_dtm_skip$User_ID = as.character(review_dtm_skip$User_ID)

review_dtm_skip <- review_dtm_skip %>% 
  ungroup() %>%
  cast_dtm(User_ID, bigram, n)


### PCA ###

N_factors   <- 6
pca_results <- prcomp(review_dtm, scale = FALSE, rank. = N_factors)  #get the 20 most important factors
rawLoadings <- pca_results$rotation[, 1:N_factors] %*% diag(pca_results$sdev, N_factors, N_factors)
rotated     <- varimax(rawLoadings)

pca_results$rotation <- rotated$loadings
pca_results$x <- scale(pca_results$x[,1:N_factors]) %*% rotated$rotmat 

# Add the factors to the data frame
lastcol    <- ncol(reviews_df)
reviews_df <- data.frame(reviews_df, factor = pca_results$x)
colnames(reviews_df)[(lastcol+1):(lastcol+N_factors)] <- paste0("factor", 1:N_factors)

# Figure out which words load high on each factor
factor_labels <- NULL 
for (j in 1:N_factors) {
  aa<-abs(pca_results$rotation[,j]) %>% sort(decreasing = TRUE) 
  factor_labels <- rbind(factor_labels, paste0(names(aa[1:8])))
}
factor_labels


### COMMON WORDS ###


counts <- colSums(as.matrix(review_dtm)) %>% sort(decreasing=TRUE)

lastcol        <- ncol(reviews_df)
N_words_stored <- 50
word_labels    <- (names(counts)[1:N_words_stored])
reviews_df     <- data.frame(reviews_df, words = as.matrix(review_dtm[,word_labels]))
names(reviews_df)[(lastcol+1):(lastcol+N_words_stored)] <- word_labels




### BIGRAMS ###


review_dtm_bi <- as.matrix(review_dtm_bi)
reviews_df <- cbind(reviews_df, review_dtm_bi[match(reviews_df$User_ID, rownames(review_dtm_bi)),])
reviews_df[is.na(reviews_df)] <- 0


### EMOTIONS ###


nrc_emotions  <- get_nrc_sentiment(reviews_df$reviewtext)

reviews_df <- data.frame(reviews_df, nrc_emotions)


### SKIP N-GRAMS ###

review_dtm_skip <- as.matrix(review_dtm_skip)
reviews_df <- cbind(reviews_df, review_dtm_skip[match(reviews_df$User_ID, rownames(review_dtm_skip)),])
reviews_df[is.na(reviews_df)] <- 0

save(reviews_df , file="reviews_with_predictor_variables.rData")
```


```{r}
### PREDICTIVE MODELLING ###

colnames(reviews_df) <- gsub(" ", "_", colnames(reviews_df))  # replace spaces in variable names
reviews_df$Rating <- ifelse(as.numeric(as.factor(reviews_df$Rating))<=3,1,2)
str(reviews_df$Rating)

N_factors <- 6 # same as line 180
N_emotions <- 10 # includes pos/neg
N_words_stored <- 50 # Specified in line 208
N_bigrams_stored <- 22 # Nr of bigrams in matrix review_dtm_bi / sel_bigrams in line 83
N_skipgrams_stores <- 17 # Nr of skip ngrams

### feature names and split sample ###
index <- 8
factornames  <- colnames(reviews_df)[index:(index+N_factors-1)]
index <- index + N_factors
wordnames    <- colnames(reviews_df)[index:(index+N_words_stored-1)]
index <- index + N_words_stored
bigramnames <- colnames(reviews_df)[index:(index+N_bigrams_stored-1)]
index <- index + N_bigrams_stored
emotionnames <- colnames(reviews_df)[index:(index+N_emotions-1)]
index <- index + N_emotions
skipgramnames <- colnames(reviews_df)[index:(index+N_skipgrams_stores-1)]
index <- index + N_skipgrams_stores

# make a balanced train set
set.seed(1234)    # fix seed to allow for results to be reproducible

test_data <- sample(1:nrow(reviews_df), size = round(0.1*nrow(reviews_df)))
train <- setdiff(1:nrow(reviews_df), test_data)
train_data <- reviews_df[train, ]
test <- reviews_df[test_data, ]

data_minority <- train_data[train_data$Rating == 1, ]
data_majority <- train_data[train_data$Rating == 2, ]
undersample_size <- nrow(data_minority)
data_majority_undersampled <- data_majority[sample(1:nrow(data_majority), undersample_size), ]
train <- rbind(data_majority_undersampled, data_minority)



allFactors <- paste("(", paste(factornames,collapse=" + "), ")")
allEmotions <- paste("(", paste(emotionnames,collapse=" + "), ")")
allWords <- paste("(", paste(wordnames,collapse=" + "), ")")
allBigrams <- paste("(", paste(bigramnames,collapse=" + "), ")")
allskipgrams <- paste("(", paste(skipgramnames,collapse=" + "), ")")
allWordsAndBigrams <- paste("(", paste(c(wordnames, bigramnames),collapse=" + "), ")")




### GENERALIZED LINEAR MODEL ###
f <- paste("(Rating == 2) ~ Nr_of_words + ", allFactors, " + ", allEmotions, " + ", allWords , " + ", allBigrams, "+", allskipgrams)
glm.all <- glm(f, data=train , family=binomial)
summary(glm.all)

f <- paste("(Rating == 2) ~ Nr_of_words + ", allFactors, " + ", allWords , " + ", allBigrams, " + ", allskipgrams)
glm.nodict <- glm(f, data=train , family = binomial)  # No dictionary
summary(glm.nodict)

f <- paste("(Rating == 2) ~  Nr_of_words + ", allFactors) 
glm.onlyfactors <- glm(f, data=train, family = binomial) # PCA
summary(glm.onlyfactors)

f <- paste("(Rating == 2) ~  Nr_of_words + ", allEmotions) 
glm.onlyemotions <- glm(f, data=train, family = binomial) # NCR
summary(glm.onlyemotions)

f <- paste("(Rating == 2) ~ Nr_of_words + ", allWords)
glm.onlywords <- glm(f, data=train, family = binomial) # Words
summary(glm.onlywords)

f <- paste("(Rating == 2) ~ Nr_of_words + ", allBigrams)
glm.bigrams <- glm(f, data=train, family = binomial) # Bigrams
summary(glm.bigrams)

f <- paste("(Rating == 2) ~ Nr_of_words + ", allWords , " + ",allBigrams)
glm.words_bigrams <- glm(f, data=train, family = binomial) # 
summary(glm.words_bigrams)

f <- paste("(Rating == 2) ~ Nr_of_words + positive + negative")
glm.posneg <- glm(f, data=train, family = binomial)
summary(glm.posneg)

f <- paste("(Rating == 2) ~ Nr_of_words + ", allskipgrams)
glm.skipgrams <- glm(f, data=train, family = binomial)
summary(glm.skipgrams)


#AIC
table_AIC <- AIC(glm.all, glm.nodict, glm.onlyfactors, glm.onlyemotions, glm.onlywords, glm.bigrams, glm.words_bigrams, glm.posneg, glm.skipgrams)


#Prediction of glm.all
dat <- data.frame(Predicted_prob=predict(glm.all, type="response"), rating = train$Rating)
table(dat$Rating)
predglm <- as.factor(predict(glm.all, type="response") > .5)
cm_all <- confusionMatrix(data = predglm,  
                reference = as.factor(train$Rating==2))

acc_all <- data.frame(
  Accuracy = cm_all$overall[1],
  Sensitivity = cm_all$byClass[1],
  Specificity = cm_all$byClass[2],
  Balanced_Accuracy = cm_all$byClass[11]
)
acc_all_t <- data.frame(t(acc_all))
colnames(acc_all_t) <- c("All")


#Prediction of glm.nodict
predglm <- as.factor(predict(glm.nodict, type="response") > .5)
cm_nodict <- confusionMatrix(data = predglm,  
                reference = as.factor(train$Rating==2))

acc_nodict <- data.frame(
  Accuracy = cm_nodict$overall[1],
  Sensitivity = cm_nodict$byClass[1],
  Specificity = cm_nodict$byClass[2],
  Balanced_Accuracy = cm_nodict$byClass[11]
)
acc_nodict_t <- data.frame(t(acc_nodict))
colnames(acc_nodict_t) <- c("NoDict")



#Prediction of glm.onlyfactors
predglm <- as.factor(predict(glm.onlyfactors, type="response") > .5)
cm_fact <- confusionMatrix(data = predglm,  
                reference = as.factor(train$Rating==2))

acc_fact <- data.frame(
  Accuracy = cm_fact$overall[1],
  Sensitivity = cm_fact$byClass[1],
  Specificity = cm_fact$byClass[2],
  Balanced_Accuracy = cm_fact$byClass[11]
)
acc_fact_t <- data.frame(t(acc_fact))
colnames(acc_fact_t) <- c("Only Factors")


#Prediction of glm.onlyemotions
predglm <- as.factor(predict(glm.onlyemotions, type="response") > .5)
cm_emo <- confusionMatrix(data = predglm,  
                reference = as.factor(train$Rating==2))

acc_emo <- data.frame(
  Accuracy = cm_emo$overall[1],
  Sensitivity = cm_emo$byClass[1],
  Specificity = cm_emo$byClass[2],
  Balanced_Accuracy = cm_emo$byClass[11]
)
acc_emo_t <- data.frame(t(acc_emo))
colnames(acc_emo_t) <- c("Only Emotions")


#Prediction of glm.onlywords
predglm <- as.factor(predict(glm.onlywords, type="response") > .5)
cm_word <- confusionMatrix(data = predglm,  
                reference = as.factor(train$Rating==2))

acc_word <- data.frame(
  Accuracy = cm_word$overall[1],
  Sensitivity = cm_word$byClass[1],
  Specificity = cm_word$byClass[2],
  Balanced_Accuracy = cm_word$byClass[11]
)
acc_word_t <- data.frame(t(acc_word))
colnames(acc_word_t) <- c("Only Words")



#Prediction of glm.bigrams
predglm <- as.factor(predict(glm.bigrams, type="response") > .5)
cm_bi <- confusionMatrix(data = predglm,  
                reference = as.factor(train$Rating==2))

acc_bi <- data.frame(
  Accuracy = cm_bi$overall[1],
  Sensitivity = cm_bi$byClass[1],
  Specificity = cm_bi$byClass[2],
  Balanced_Accuracy = cm_bi$byClass[11]
)
acc_bi_t <- data.frame(t(acc_bi))
colnames(acc_bi_t) <- c("Bigrams")



#Prediction of glm.posneg
predglm <- as.factor(predict(glm.posneg, type="response") > .5)
cm_posneg <- confusionMatrix(data = predglm,  
                reference = as.factor(train$Rating==2))

acc_posneg <- data.frame(
  Accuracy = cm_posneg$overall[1],
  Sensitivity = cm_posneg$byClass[1],
  Specificity = cm_posneg$byClass[2],
  Balanced_Accuracy = cm_posneg$byClass[11]
)
acc_posneg_t <- data.frame(t(acc_posneg))
colnames(acc_posneg_t) <- c("Posneg")



#Prediction of glm.skipgrams
predglm <- as.factor(predict(glm.skipgrams, type="response") > .5)
cm_nskip <- confusionMatrix(data = predglm,  
                reference = as.factor(train$Rating==2))

acc_nskip <- data.frame(
  Accuracy = cm_nskip$overall[1],
  Sensitivity = cm_nskip$byClass[1],
  Specificity = cm_nskip$byClass[2],
  Balanced_Accuracy = cm_nskip$byClass[11]
)
acc_nskip_t <- data.frame(t(acc_nskip))
colnames(acc_nskip_t) <- c("Skipgram")

CM_ALL <- cbind(acc_all_t, acc_nodict_t, acc_fact_t, acc_emo_t, acc_word_t, acc_bi_t, acc_posneg_t, acc_nskip_t)

```



```{r}
### LASSO FOR LOGIT ###
# Use optimal model based on AIC = glm.all
f = paste("~ 0 + Nr_of_words + ", allFactors, " * ", allEmotions, " + ", allWords, " + ", allBigrams, "+", allskipgrams)
LargeX <- model.matrix(formula(f), data=train)
LargeTest <- model.matrix(formula(f), data=test)

y <- as.factor(train$Rating)
cvfit.glm <- cv.glmnet(LargeX, y, family="binomial", alpha = 1)
lasso.glm <- glmnet(LargeX, y, family="binomial", alpha = 1)

plot(lasso.glm)
plot(cvfit.glm)

par <- predict(lasso.glm, s = cvfit.glm$lambda.min, type='coefficients')
nnzero(par)
length(par)

lasso.glm.pred <- predict(lasso.glm, s = cvfit.glm$lambda.1se, type="response", newx = LargeX)
lasso.glm.pred.test <- predict(lasso.glm, s = cvfit.glm$lambda.1se,type="response", newx = LargeTest)


pred_train <- ifelse(lasso.glm.pred > 0.5, 1, 0)
table(Actual = train$Rating, Predicted = pred_train)

pred_test <- ifelse(lasso.glm.pred.test > 0.5, 2, 1)

cm_lasso <- confusionMatrix(data = as.factor(pred_test),  
                reference = as.factor(test$Rating))

acc_lasso <- data.frame(
  Accuracy = cm_lasso$overall[1],
  Sensitivity = cm_lasso$byClass[1],
  Specificity = cm_lasso$byClass[2],
  Balanced_Accuracy = cm_lasso$byClass[11]
)
acc_lasso_t <- data.frame(t(acc_lasso))
colnames(acc_lasso_t) <- c("Lasso")

best_lambda <- cvfit.glm$lambda.min


### RANDOM FOREST ###

f = paste("as.factor(Rating) ~ Nr_of_words + ", allFactors, " * ", allEmotions, " + ", allWords, " + ", allBigrams, "+", allskipgrams)
rf = randomForest(formula(f),  
                  ntree = 100,
                  data = train)

varImpPlot(rf,  
           sort = TRUE,
           n.var = 15,
           main = "Top 15 - Variable Importance")


#out of bag
pred.alt <- predict(rf)
confusionMatrix(data = pred.alt,  
                reference = as.factor(train$Rating))

#estimation sample
pred.est <- predict(rf, train)
confusionMatrix(data = pred.est,  
                reference = as.factor(train$Rating))

#test sample
pred.test <- predict(rf, test)
cm_rf <- confusionMatrix(data = pred.test,  
                reference = as.factor(test$Rating))


acc_rf <- data.frame(
  Accuracy = cm_rf$overall[1],
  Sensitivity = cm_rf$byClass[1],
  Specificity = cm_rf$byClass[2],
  Balanced_Accuracy = cm_rf$byClass[11]
)
acc_rf_t <- data.frame(t(acc_rf))
colnames(acc_rf_t) <- c("RF")

CM_GLM_RF <- cbind(acc_all_t, acc_lasso_t, acc_rf_t)
```




# Appendix B

```{r, echo = FALSE}
kable(table_AIC, caption = 'AIC score of GLM', digits = 2)
kable(CM_ALL, caption = 'Accuracy of GLM', digits = 2 )
kable(CM_GLM_RF, caption = 'Accuracy of GLM, LASSO AND RF', digits = 2)


varImpPlot(rf,  
           sort = TRUE,
           n.var = 10,
           main = "Figure 1: Top 10 - Variable Importance")


```



